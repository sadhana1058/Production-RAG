# Production-RAG
## Archtecture
rag-service/
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ crawler
â”‚   â”œâ”€â”€ cleaner
â”‚   â”œâ”€â”€ chunker
â”‚   â””â”€â”€ embedder
â”‚
â”œâ”€â”€ knowledge/
â”‚   â”œâ”€â”€ vector_store
â”‚   â””â”€â”€ metadata_index
â”‚
â”œâ”€â”€ rag_engine/
â”‚   â”œâ”€â”€ retriever
â”‚   â”œâ”€â”€ guardrails
â”‚   â”œâ”€â”€ prompt_builder
â”‚   â””â”€â”€ generator
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ routes
â”‚   â”œâ”€â”€ schemas
â”‚   â””â”€â”€ auth
â”‚
â”œâ”€â”€ observability/
â”‚   â”œâ”€â”€ logging
â”‚   â””â”€â”€ metrics
â”‚
â””â”€â”€ deployment/
    â”œâ”€â”€ docker
    â””â”€â”€ compose

ğŸ“˜ Enterprise Policy Intelligence RAG API

A production-grade Retrieval-Augmented Generation (RAG) service that enables accurate, source-grounded, and auditable Q&A over enterprise policy documents, built using the public GitLab Handbook as a real-world knowledge base.

This system is designed to mirror how RAG is implemented in real companies, with guardrails, observability, async ingestion, and API-first design â€” not a toy chatbot.

ğŸš€ Problem Statement

In large organizations, employees frequently struggle to find accurate answers across:

HR policies

Security & compliance guidelines

Finance and expense rules

Legal and operational SOPs

Naive LLM chatbots:

Hallucinate answers

Ignore source verification

Lack auditability

This project solves that by enforcing retrieval-only answers, confidence-based refusal, and full observability.

ğŸ§  Solution Overview

This service:

Indexes enterprise policy documents (GitLab Handbook)

Retrieves only relevant, high-confidence context

Generates answers strictly grounded in source documents

Refuses to answer when information is missing

Logs and monitors every decision

ğŸ—ï¸ System Architecture
rag-service/
â”‚
â”œâ”€â”€ ingestion/          # Offline async document ingestion
â”‚   â”œâ”€â”€ crawler         # Fetch handbook pages
â”‚   â”œâ”€â”€ cleaner         # Remove HTML noise
â”‚   â”œâ”€â”€ chunker         # Semantic chunking
â”‚   â””â”€â”€ embedder        # Vector embedding
â”‚
â”œâ”€â”€ knowledge/          # Knowledge persistence
â”‚   â”œâ”€â”€ vector_store    # FAISS / ChromaDB
â”‚   â””â”€â”€ metadata_index  # Structured metadata
â”‚
â”œâ”€â”€ rag_engine/         # Core intelligence
â”‚   â”œâ”€â”€ retriever       # Top-K + threshold retrieval
â”‚   â”œâ”€â”€ guardrails      # Hallucination & safety checks
â”‚   â”œâ”€â”€ prompt_builder  # Controlled prompt construction
â”‚   â””â”€â”€ generator       # LLM interaction + citations
â”‚
â”œâ”€â”€ api/                # FastAPI service
â”‚   â”œâ”€â”€ routes          # REST endpoints
â”‚   â”œâ”€â”€ schemas         # Typed request/response models
â”‚   â””â”€â”€ auth            # JWT / API key support
â”‚
â”œâ”€â”€ observability/      # Monitoring & debugging
â”‚   â”œâ”€â”€ logging         # Structured logs
â”‚   â””â”€â”€ metrics         # Prometheus metrics
â”‚
â””â”€â”€ deployment/         # Containerization
    â”œâ”€â”€ docker
    â””â”€â”€ compose

ğŸ” Key Features
âœ… Retrieval-Only Answers

LLM can only answer using retrieved handbook content

No external knowledge allowed

ğŸ›‘ Hallucination Guardrails

Confidence threshold enforced

Low-confidence queries return a refusal

Prevents â€œmade-upâ€ answers

ğŸ“œ Source Citations

Every answer includes:

Document title

URL

Section reference

ğŸ” Metadata-Aware Retrieval

Filters by:

Department (HR, Finance, Security)

Document type

Version

ğŸ“Š Observability & Metrics

Retrieval hit rate

Refusal rate

Query latency

Top failed queries

âš™ï¸ Async Ingestion

Decouples slow ingestion from fast queries

Mirrors real production pipelines

ğŸ“‚ Data Source

This project uses real enterprise documentation from:

GitLab public handbook:

HR policies

Finance & expense guidelines

Security & compliance documentation

Legal policies

These documents closely resemble internal corporate knowledge bases used in production systems.

ğŸ”Œ API Endpoints
Method	Endpoint	Description
POST	/rag/query	Ask a policy question
POST	/rag/ingest	Trigger document ingestion
GET	/health	Service health check
GET	/metrics	Prometheus metrics
ğŸ§ª Example Query

User

What expenses are reimbursable under GitLabâ€™s policy?


Response

{
  "answer": "GitLab reimburses business-related travel, meals, and lodging expenses when pre-approved...",
  "sources": [
    {
      "title": "Expense Reimbursement Policy",
      "url": "https://about.gitlab.com/handbook/finance/expenses/"
    }
  ],
  "confidence": "high"
}

ğŸ§° Tech Stack (All Free / Open Source)

Backend: FastAPI

Embeddings: sentence-transformers (MiniLM)

Vector Store: FAISS / ChromaDB

LLM: Local (Ollama) or free-tier hosted

Monitoring: Prometheus + Grafana

Containerization: Docker

ğŸ§  Design Decisions

Ingestion separated from query path â†’ scalable & reliable

Guardrails before generation â†’ reduced hallucinations

Metadata-driven retrieval â†’ enterprise realism

Observability built-in â†’ debuggable AI

ğŸ“ˆ Evaluation Strategy

Gold-standard policy queries

Retrieval confidence tracking

Refusal correctness validation

Latency benchmarks

Future Enhancements

Role-based access control (RBAC)

Multi-tenant document indexing

Slack / Web UI integration

Continuous ingestion with diff detection

Automated retrieval quality evaluation